{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= ChatOpenAI(model_name=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets go Step by Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello Vikas! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 13, 'total_tokens': 24}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-36166270-a8c1-4a23-b9fa-fa200c64042b-0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi, I am Vikas\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now lets check if it remembers my name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm sorry, I am not able to know your name as I am an AI assistant.\", response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 11, 'total_tokens': 30}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-07a39054-1cfe-4a52-9560-4c7458b59f57-0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.invoke([HumanMessage(content=\"Whats my name?\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It didn't remember the name\n",
    "    * Now we will save some predefined chat and ask the model if it remembers old chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Vikas.', response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 35, 'total_tokens': 41}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-8c60a6c2-10c2-4e66-b74a-20c1ac862f50-0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi! I'm Vikas\"),\n",
    "        AIMessage(content=\"Hello Vikas! How can i help you?\"),\n",
    "        HumanMessage(content=\"What's my name\")\n",
    "        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now it is remembering the name\n",
    "* So Chatbot has to have previous messages to remember what we have told\n",
    "#### Lets Streamline this\n",
    "\n",
    "* We will store our chat in data store and use it for future interactions by retrieving them and pass them into chain as part of input.\n",
    "* We will manage this with session ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "store= {}\n",
    "## Get session history would give you the chat history of the session or it will store it if it is new\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]= ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "## Managing chat: Where storing and appending new chat happens here\n",
    "with_message_history= RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We will create config now that we have to pass into runnables everytime. This config consists of session id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "config= {\"configurable\": {\"session_id\": \"vikas\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 892271da-2437-4afb-adba-c7ce312b768c not found for run fab5071c-a8be-4d4a-8d73-ff3d0b772431. Treating as a root run.\n"
     ]
    }
   ],
   "source": [
    "response= with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hello, I'm Vikas\")\n",
    "    ],\n",
    "    config=config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nice to meet you Vikas! How can I help you today?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now lets ask my name again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 75bbe2e1-2a7e-4747-8c6d-c77a7c48b50e not found for run 4495bb6e-5a09-4c2e-a357-253c709a7cdb. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Vikas.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response= with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"What is my name\")\n",
    "    ], config= config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cool! Now the chat remembers history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Lets change the session id and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run c7247948-8de3-4589-8fae-81de60d39fe8 not found for run fceed298-f397-4ffb-8fae-9717de453b84. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I am not able to know your name as we are communicating textually.\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_2= {\"configurable\": {\"session_id\": \"vicky\"}}\n",
    "response= with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"What is my name?\")\n",
    "    ], config= config_2\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now lets goback and ask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 6e37ce29-18e1-45ba-91db-18bd780737d5 not found for run fce58b8c-73cf-4149-b5e9-ce13f134f20d. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I am not able to know your name as we are communicating textually.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "respose= with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"What is my name?\")\n",
    "        \n",
    "    ],\n",
    "    config= config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is very basic layer of the chat history\n",
    "### Lets dig more into it and understand\n",
    "* We will find a way to attach history to prompt template as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt= ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            # \"you are a helpful assistant. Answer all the questions to the best of your ability.\"\n",
    "            template\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "chain= prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Vikas! How can I assist you today?'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response= chain.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Hi! I'm vikas\")\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "response.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets add message history to the chat\n",
    "* We will create Runnablewithhistory but instead of model we will pass chain as parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history= RunnableWithMessageHistory(chain, get_session_history)\n",
    "config= {\"configurable\": {\"session_id\":\"vikas\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" You are certificate generator expert.\\nYou collect details from input to create certificate mentioned below along with the list of details required from user\\n\\n\\nBelow are the types of certificates:\\n\\n\\n\\nEmployment Resignation:\\nThis certificate generates resignation details of employee. If language is German then Formular id= ARB_AUS else Formular id= ARB_AUS_EN and generates certificate provided below information:\\n1. Employee Id: \\n2. Bv Number:\\n3. Effective Date (YYYY-MM-DD):\\n4. Language (English or German): \\n\\nIf all the necessary values are provided then covert the result in url format with prefix https://certificates/certificate name/certificate details seperated by '/'.\\n\\n\\nEmployment details:\\nThis certificate generates employment details of employee requested. If language is German then Formular id= ARB_ESS else Formular id= ARB_ESS_EN and generates certificate provided below information:\\n1. Employee Id: \\n2. Bv Number:\\n3. Effective Date (YYYY-MM-DD):\\n4. Language (English or German): \\n   \\nIf all the necessary values are provided then covert the result in url format with prefix https://certificates/certificate name/certificate details seperated by '/'.\\n\\n\""
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run da6fe4b4-431b-48fb-8b40-00eab2f41c2c not found for run fb4910cd-3279-43c8-b25f-07eb2fbdefd2. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nAI: Yes, I can create various types of certificates. Please let me know which type of certificate you would like me to generate.'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response= with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Can you create certificates?\")\n",
    "    ],\n",
    "    config= config\n",
    ")\n",
    "\n",
    "# response.content\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run bdb0eb84-36ba-45fa-84b9-36162eedf8a7 not found for run 545fe9da-1477-4cf8-95d3-7764fd9b0c1e. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Vikas.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response= with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"What is my name\")\n",
    "    ],\n",
    "    config= config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super! Lets add few other parameters such as respond in different language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt= ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all question tp best of your ability in {language}.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "chain= prompt| model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¡Hola, Vikas! ¿En qué puedo ayudarte hoy?'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response= chain.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"Hello, I'm Vikas\")], \"language\": \"Spanish\"\n",
    "        }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create runnable char history\n",
    "with_message_history= RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "config= {\"configurable\": {\"session_id\":\"vikas\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 547af9f6-73aa-4af9-ae1c-200332e6226a not found for run f280e049-b033-441b-97e5-b3159912d62c. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Nice to meet you Vikas! How can I help you today?'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response= with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"Hello, I'm Vikas\")], \"language\": \"Spanish\"\n",
    "        }, config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 07f1a320-d82e-4776-a531-093084cb325e not found for run 37aab3e0-700e-450e-a558-0ce0f05a930c. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Vikas.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response= with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"What is my name?\")\n",
    "        ], \"language\":\"Spanish\"\n",
    "    }, config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing Chat history\n",
    "* We can add chat history like above. But what if storing goes on for all the chat. \n",
    "    * Memory issue\n",
    "    * Overflowing of the context window of LLM\n",
    "* So We will add a step to limit the size of the messages that we are passing in\n",
    "* This has to be done Before the prompt template, but After loading messages from message history.\n",
    "* We can do this by creating a function to select k most recent messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def filter_messages(messages, k=10):\n",
    "    return messages[-k:]\n",
    "\n",
    "chain= (\n",
    "    RunnablePassthrough.assign(messages= lambda x: filter_messages(x[\"messages\"]))\n",
    "    | prompt\n",
    "    | model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    HumanMessage(content=\"hi! I'm Vikas\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like butterscotch ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I don't have access to that information.\""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response =  chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"What is my name\")],\n",
    "        \"language\":\"English\"\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is because The limit is 10 and the entered messages is 11th so it left the first message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your favorite ice cream flavor is butterscotch.'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response =  chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"What is my Fav ice Cream\")],\n",
    "        \"language\":\"English\"\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The response was within the chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets Wrap with message history with session id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history= RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")\n",
    "config= {\"configurable\": {\"session_id\": \"vikas\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 0b83f644-f02d-4b8b-882d-0b2ee771f719 not found for run daf71cf2-f1d1-4abf-a7b8-47ecd721a421. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Vikas.'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response= with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"What is my name?\")\n",
    "        ], \"language\":\"english\"\n",
    "    }, config= config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run c16e2839-e503-4e07-bf11-23c4e903ec78 not found for run 4178130e-1340-4655-9291-94c1a8ca8a3b. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I don't have that information. Could you please tell me what your favorite ice cream flavor is?\""
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response= with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"What is my favourite ice cream?\")\n",
    "        ], \"language\":\"english\"\n",
    "    }, config= config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run a51f764b-a2b9-4694-8c62-a2cb63cb48ac not found for run 2a4d82f7-d246-4cd0-9d69-2f114c9a19a2. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's great! Butter scotch is a delicious choice for an ice cream flavor.\""
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response= with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"It is butter scotch?\")\n",
    "        ], \"language\":\"english\"\n",
    "    }, config= config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 8a0f7d6e-7d91-44f8-9164-6812c2b0d5d4 not found for run f1437241-7578-4049-9839-de20cbef020e. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your favorite ice cream flavor is butter scotch.'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response= with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Can you tell me now, what is my favourite ice cream?\")\n",
    "        ], \"language\":\"english\"\n",
    "    }, config= config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 96cb9944-b889-4a86-8e2e-cc36f38dd289 not found for run 4797d4f1-0d3c-4005-a6f3-9fdfd14a6f1a. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "''\n",
      "'Hi'\n",
      "' Todd'\n",
      "'!'\n",
      "' Sure'\n",
      "','\n",
      "' here'\n",
      "\"'s\"\n",
      "' a'\n",
      "' joke'\n",
      "' for'\n",
      "' you'\n",
      "':'\n",
      "' Why'\n",
      "' did'\n",
      "' the'\n",
      "' math'\n",
      "' book'\n",
      "' look'\n",
      "' sad'\n",
      "'?'\n",
      "' Because'\n",
      "' it'\n",
      "' had'\n",
      "' too'\n",
      "' many'\n",
      "' problems'\n",
      "'.'\n",
      "' 😄'\n",
      "''\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "config = {\"configurable\": {\"session_id\": \"abc15\"}}\n",
    "for r in with_message_history.stream(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"hi! I'm todd. tell me a joke\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    "):\n",
    "    pprint(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_openai import OpenAI\n",
    "### Packages which handle Chat history\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.messages import HumanMessage\n",
    "##Chat prompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo')\n",
    "## Define LLLM congifuration\n",
    "template = \"\"\"\n",
    "You are creating a Certificate of Employment for an employee. Please provide the following details:\n",
    "\n",
    "Employment Resignation:\n",
    "This certificate generates resignation details of employee. If language is German then Formular id= ARB_AUS else Formular id= ARB_AUS_EN and generates certificate provided below information:\n",
    "1. Employee Id: \n",
    "2. Bv Number:\n",
    "3. Effective Date (YYYY-MM-DD):\n",
    "4. Language (English or German): \n",
    "\n",
    "If all the necessary values are provided then covert the result in url format with prefix https://certificates/certificate name/certificate details seperated by '/'.\n",
    "\n",
    "\n",
    "Employment details:\n",
    "This certificate generates employment details of employee requested. If language is German then Formular id= ARB_ESS else Formular id= ARB_ESS_EN and generates certificate provided below information:\n",
    "1. Employee Id: \n",
    "2. Bv Number:\n",
    "3. Effective Date (YYYY-MM-DD):\n",
    "4. Language (English or German): \n",
    "\n",
    "Please provide each detail one by one in the given order. If you have any questions or need clarification, feel free to ask!\n",
    "\n",
    "\"\"\"\n",
    "# Now we can override it and set it to \"Friend\"\n",
    "# from langchain_core.prompts.prompt import PromptTemplate\n",
    "\n",
    "prompt =    ChatPromptTemplate.from_messages( [\n",
    "        (\n",
    "            \"system\",\n",
    "            template\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "### Lets Create Chain\n",
    "chain= prompt | llm\n",
    "\n",
    "### Chat message history\n",
    "## Function that stores chat based on session id\n",
    "store= {}\n",
    "## Get session history would give you the chat history of the session or it will store it if it is new\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]= ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history= RunnableWithMessageHistory(\n",
    "    chain, get_session_history,\n",
    "       \n",
    ")\n",
    "## Create session id configuration\n",
    "config= {\"configurable\": {\"session_id\":\"vikas\"}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text= \"Hi i am Vikas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run b576c209-ae9c-4b43-8ee7-0a5848b5a04c not found for run 54b4dc74-0f48-4b21-a542-281ab1c91a6e. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Vikas! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "response= with_message_history.invoke(\n",
    "    {\n",
    "        \"message\": HumanMessage(content= input_text)\n",
    "    }, config= config\n",
    ")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "template = \"\"\"\n",
    "You are creating a Certificate of Employment for an employee. Please provide the following details:\n",
    "\n",
    "Employment Resignation:\n",
    "This certificate generates resignation details of employee. If language is German then Formular id= ARB_AUS else Formular id= ARB_AUS_EN and generates certificate provided below information:\n",
    "1. Employee Id: \n",
    "2. Bv Number:\n",
    "3. Effective Date (YYYY-MM-DD):\n",
    "4. Language (English or German): \n",
    "\n",
    "If all the necessary values are provided then covert the result in url format with prefix https://certificates/certificate name/certificate details seperated by '/'.\n",
    "\n",
    "\n",
    "Employment details:\n",
    "This certificate generates employment details of employee requested. If language is German then Formular id= ARB_ESS else Formular id= ARB_ESS_EN and generates certificate provided below information:\n",
    "1. Employee Id: \n",
    "2. Bv Number:\n",
    "3. Effective Date (YYYY-MM-DD):\n",
    "4. Language (English or German): \n",
    "\n",
    "Please provide each detail one by one in the given order. If you have any questions or need clarification, feel free to ask!\n",
    "\"\"\"\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_template(template)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_privacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
